{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41e4feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T14:58:32.948578Z",
     "iopub.status.busy": "2024-08-05T14:58:32.948198Z",
     "iopub.status.idle": "2024-08-05T15:00:58.828141Z",
     "shell.execute_reply": "2024-08-05T15:00:58.826816Z"
    },
    "papermill": {
     "duration": 145.898456,
     "end_time": "2024-08-05T15:00:58.830790",
     "exception": false,
     "start_time": "2024-08-05T14:58:32.932334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q vllm \\\n",
    "    -U --no-index --find-links /kaggle/input/vllm-wheel/vllm-wheel-files\n",
    "!pip install -q langchain-text-splitters ipywidgets \\\n",
    "    -U --no-index --find-links /kaggle/input/text-splitters/text-splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6461fd",
   "metadata": {
    "papermill": {
     "duration": 0.014021,
     "end_time": "2024-08-05T15:00:58.859975",
     "exception": false,
     "start_time": "2024-08-05T15:00:58.845954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c18f0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:00:58.891178Z",
     "iopub.status.busy": "2024-08-05T15:00:58.890853Z",
     "iopub.status.idle": "2024-08-05T15:01:03.562769Z",
     "shell.execute_reply": "2024-08-05T15:01:03.561945Z"
    },
    "papermill": {
     "duration": 4.690826,
     "end_time": "2024-08-05T15:01:03.564975",
     "exception": false,
     "start_time": "2024-08-05T15:00:58.874149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from threading import Thread\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_math_sdp(False)\n",
    "\n",
    "if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327b44c",
   "metadata": {
    "papermill": {
     "duration": 0.014007,
     "end_time": "2024-08-05T15:01:03.593351",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.579344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b668a5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.622646Z",
     "iopub.status.busy": "2024-08-05T15:01:03.622148Z",
     "iopub.status.idle": "2024-08-05T15:01:03.627278Z",
     "shell.execute_reply": "2024-08-05T15:01:03.626403Z"
    },
    "papermill": {
     "duration": 0.021848,
     "end_time": "2024-08-05T15:01:03.629128",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.607280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class constants:\n",
    "    MODEL_PATH = '/kaggle/input/model/transformers/phi-3-mini-4k-instruct/1'\n",
    "    TEST_PATH = '/kaggle/input/lmsys-chatbot-arena/test.csv'\n",
    "#     TEST_PATH = '/kaggle/input/lmsys-chatbot-arena/train.csv'\n",
    "    SUBMISSION_PATH = 'submission.csv'\n",
    "    TARGETS = ['winner_model_a','winner_model_b','winner_tie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe5dea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.658718Z",
     "iopub.status.busy": "2024-08-05T15:01:03.658416Z",
     "iopub.status.idle": "2024-08-05T15:01:03.663170Z",
     "shell.execute_reply": "2024-08-05T15:01:03.662324Z"
    },
    "papermill": {
     "duration": 0.021506,
     "end_time": "2024-08-05T15:01:03.665098",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.643592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class config:\n",
    "    SPREAD_MAX_LENGTH = False\n",
    "    MAX_LENGTH=False\n",
    "    MAX_NEW_TOKENS = 32\n",
    "    MAX_TEXT_SIZE=4500\n",
    "    MAX_TOKENS = 4096\n",
    "    BATCH_SIZE = 50\n",
    "    USE_CACHE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4274d2ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.695127Z",
     "iopub.status.busy": "2024-08-05T15:01:03.694682Z",
     "iopub.status.idle": "2024-08-05T15:01:03.698632Z",
     "shell.execute_reply": "2024-08-05T15:01:03.697791Z"
    },
    "papermill": {
     "duration": 0.02098,
     "end_time": "2024-08-05T15:01:03.700420",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.679440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device0 = torch.device('cuda:0')\n",
    "device1 = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122cce8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.730221Z",
     "iopub.status.busy": "2024-08-05T15:01:03.729962Z",
     "iopub.status.idle": "2024-08-05T15:01:03.735804Z",
     "shell.execute_reply": "2024-08-05T15:01:03.734956Z"
    },
    "papermill": {
     "duration": 0.023035,
     "end_time": "2024-08-05T15:01:03.737775",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.714740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_template(query:str, response_a:str, response_b:str)->str:\n",
    "    return f'''Act as a discriminator assistant to evaluate and distinguish between two responses for a given query.\n",
    "    \n",
    "### Overview:\n",
    "You will be provided with a query and two responses. Your task is to compare the responses based on various criteria and determine which one is superior in each aspect.\n",
    "\n",
    "The criteria are:\n",
    "1. Relevance: Which response directly addresses the query better and provides more pertinent information?\n",
    "2. Accuracy: Which response contains more reliable and factual information based on credible sources?\n",
    "3. Clarity: Which response is more straightforward, easy to understand, and free of ambiguity?\n",
    "4. Logical Flow: Which response presents information in a more organized and coherent manner?\n",
    "5. Responsiveness: Which response better addresses specific details and aspects of the query?\n",
    "\n",
    "For each criterion, assign one of the following ratings:\n",
    "A: Response A is superior\n",
    "B: Response B is superior\n",
    "AB: Both responses are equally optimal\n",
    "NA: Neither response is satisfactory\n",
    "\n",
    "Output:\n",
    "Always provide output as a comma-separated list of ratings, corresponding to the order of criteria listed above.\n",
    "\n",
    "For example: \n",
    "Output: A,A,NA,AB,B\n",
    "\n",
    "where the 1st posn, A means response A is more relevant than the B,\n",
    "The 2nd posn, A means response A is more accurate compared to B,\n",
    "then Third, NA means neither of A or B have clarity in their response, \n",
    "and so on...\n",
    "\n",
    "###IMPORTANT NOTES:\n",
    "- Do not include any explanations or additional text. Simply provide the comma seperated ratings.\n",
    "- The order of ratings should match the order of criteria listed above.\n",
    "- There must be exactly 5 ratings in the output.\n",
    "\n",
    "### Task:\n",
    "- Query: {query}\n",
    "- Response A: {response_a}\n",
    "- Response B: {response_b}\n",
    "Output:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85813c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.767808Z",
     "iopub.status.busy": "2024-08-05T15:01:03.767532Z",
     "iopub.status.idle": "2024-08-05T15:01:03.771308Z",
     "shell.execute_reply": "2024-08-05T15:01:03.770459Z"
    },
    "papermill": {
     "duration": 0.021065,
     "end_time": "2024-08-05T15:01:03.773321",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.752256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_prompt_template = '''<|system|>\n",
    "You are a helpful assistant.<|end|>\n",
    "<|user|>\n",
    "{0}<|end|>\n",
    "<|assistant|>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e017ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.803024Z",
     "iopub.status.busy": "2024-08-05T15:01:03.802766Z",
     "iopub.status.idle": "2024-08-05T15:01:03.806224Z",
     "shell.execute_reply": "2024-08-05T15:01:03.805495Z"
    },
    "papermill": {
     "duration": 0.020494,
     "end_time": "2024-08-05T15:01:03.808089",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.787595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bnb_config = BitsAndBytesConfig(\n",
    "# #     load_in_4bit=True,\n",
    "# #     bnb_4bit_compute_dtype=torch.float16,\n",
    "# #     bnb_4bit_use_double_quant=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdcb9f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.838072Z",
     "iopub.status.busy": "2024-08-05T15:01:03.837388Z",
     "iopub.status.idle": "2024-08-05T15:01:03.841624Z",
     "shell.execute_reply": "2024-08-05T15:01:03.840803Z"
    },
    "papermill": {
     "duration": 0.021237,
     "end_time": "2024-08-05T15:01:03.843417",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.822180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "#     \"gpu_memory_utilization\": 0.99,\n",
    "#     \"tensor_parallel_size\": 1,\n",
    "    \"max_model_len\":config.MAX_TOKENS,\n",
    "    \"enable_prefix_caching\": False,\n",
    "    \"dtype\": torch.float16,\n",
    "    \"trust_remote_code\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d09b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.873220Z",
     "iopub.status.busy": "2024-08-05T15:01:03.872516Z",
     "iopub.status.idle": "2024-08-05T15:01:03.878171Z",
     "shell.execute_reply": "2024-08-05T15:01:03.877538Z"
    },
    "papermill": {
     "duration": 0.022416,
     "end_time": "2024-08-05T15:01:03.879944",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.857528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_params = {\n",
    "    \"n\": 1,\n",
    "    \"best_of\": 1,\n",
    "    \"presence_penalty\": 0.0,\n",
    "    \"frequency_penalty\": 0.0,\n",
    "    \"repetition_penalty\": 1.0,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": -1,\n",
    "    \"min_p\": 0.0,\n",
    "    \"use_beam_search\": False,\n",
    "    \"length_penalty\": 1.0,\n",
    "    \"early_stopping\": False,\n",
    "    \"stop\": [],\n",
    "    \"stop_token_ids\": [],\n",
    "    \"include_stop_str_in_output\": False,\n",
    "    \"ignore_eos\": False,\n",
    "    \"max_tokens\": config.MAX_NEW_TOKENS,\n",
    "    \"logprobs\": None,\n",
    "    \"prompt_logprobs\": None,\n",
    "    \"skip_special_tokens\": True,\n",
    "    \"spaces_between_special_tokens\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab927b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.909001Z",
     "iopub.status.busy": "2024-08-05T15:01:03.908747Z",
     "iopub.status.idle": "2024-08-05T15:01:03.912645Z",
     "shell.execute_reply": "2024-08-05T15:01:03.911787Z"
    },
    "papermill": {
     "duration": 0.020733,
     "end_time": "2024-08-05T15:01:03.914700",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.893967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(**sampling_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f0e68",
   "metadata": {
    "papermill": {
     "duration": 0.014739,
     "end_time": "2024-08-05T15:01:03.944154",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.929415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining Models and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d1831f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:03.973042Z",
     "iopub.status.busy": "2024-08-05T15:01:03.972805Z",
     "iopub.status.idle": "2024-08-05T15:01:04.095111Z",
     "shell.execute_reply": "2024-08-05T15:01:04.094166Z"
    },
    "papermill": {
     "duration": 0.138941,
     "end_time": "2024-08-05T15:01:04.097149",
     "exception": false,
     "start_time": "2024-08-05T15:01:03.958208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaner():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "cleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e78fdecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:01:04.126787Z",
     "iopub.status.busy": "2024-08-05T15:01:04.126458Z",
     "iopub.status.idle": "2024-08-05T15:02:08.126382Z",
     "shell.execute_reply": "2024-08-05T15:02:08.125374Z"
    },
    "papermill": {
     "duration": 64.017692,
     "end_time": "2024-08-05T15:02:08.129232",
     "exception": false,
     "start_time": "2024-08-05T15:01:04.111540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 08-05 15:01:04 config.py:1425] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 08-05 15:01:04 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='/kaggle/input/model/transformers/phi-3-mini-4k-instruct/1', speculative_config=None, tokenizer='/kaggle/input/model/transformers/phi-3-mini-4k-instruct/1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=/kaggle/input/model/transformers/phi-3-mini-4k-instruct/1, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 08-05 15:01:04 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 08-05 15:01:04 selector.py:54] Using XFormers backend.\n",
      "INFO 08-05 15:01:06 model_runner.py:680] Starting to load model /kaggle/input/model/transformers/phi-3-mini-4k-instruct/1...\n",
      "INFO 08-05 15:01:06 selector.py:151] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 08-05 15:01:06 selector.py:54] Using XFormers backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9ea8f14cc5470a87157966aa4af019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-05 15:01:48 model_runner.py:692] Loading model weights took 7.1183 GB\n",
      "INFO 08-05 15:01:50 gpu_executor.py:102] # GPU blocks: 978, # CPU blocks: 682\n",
      "INFO 08-05 15:01:53 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 08-05 15:01:53 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 08-05 15:02:08 model_runner.py:1181] Graph capturing finished in 15 secs.\n"
     ]
    }
   ],
   "source": [
    "model_0 = LLM(constants.MODEL_PATH,\n",
    "#               device=device0,\n",
    "              **params\n",
    "              )       \n",
    "\n",
    "# model_1 = LLM(constants.MODEL_PATH,\n",
    "#               device=device1,\n",
    "#               **params\n",
    "#               )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec39f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.164954Z",
     "iopub.status.busy": "2024-08-05T15:02:08.164094Z",
     "iopub.status.idle": "2024-08-05T15:02:08.351167Z",
     "shell.execute_reply": "2024-08-05T15:02:08.350160Z"
    },
    "papermill": {
     "duration": 0.207024,
     "end_time": "2024-08-05T15:02:08.353227",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.146203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf28c7b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.385960Z",
     "iopub.status.busy": "2024-08-05T15:02:08.385668Z",
     "iopub.status.idle": "2024-08-05T15:02:08.390879Z",
     "shell.execute_reply": "2024-08-05T15:02:08.389994Z"
    },
    "papermill": {
     "duration": 0.023651,
     "end_time": "2024-08-05T15:02:08.392918",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.369267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_text(text):\n",
    "# Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=config.MAX_TEXT_SIZE,  # desired chunk size\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    # Split the text\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13bc85f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.426121Z",
     "iopub.status.busy": "2024-08-05T15:02:08.425317Z",
     "iopub.status.idle": "2024-08-05T15:02:08.431445Z",
     "shell.execute_reply": "2024-08-05T15:02:08.430610Z"
    },
    "papermill": {
     "duration": 0.025031,
     "end_time": "2024-08-05T15:02:08.433334",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.408303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_prompt(queries, responses_a, responses_b):\n",
    "    text = [\n",
    "        model_prompt_template.format(\n",
    "            prompt_template(chunk_text(query), \n",
    "                            chunk_text(response_a), \n",
    "                            chunk_text(response_b))\n",
    "        ) for query, response_a, response_b in zip(queries, responses_a, responses_b)\n",
    "    ]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "934cf048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.465994Z",
     "iopub.status.busy": "2024-08-05T15:02:08.465343Z",
     "iopub.status.idle": "2024-08-05T15:02:08.475713Z",
     "shell.execute_reply": "2024-08-05T15:02:08.474836Z"
    },
    "papermill": {
     "duration": 0.028623,
     "end_time": "2024-08-05T15:02:08.477661",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.449038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def get_llm_response(df, model, device, batch_size=config.BATCH_SIZE):\n",
    "    results_list = []\n",
    "    predictions = []\n",
    "    cleaner()\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        cleaner()\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        prompts = tmp['prompt'].to_list()\n",
    "        with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):\n",
    "            outputs = model.generate(prompts, sampling_params)\n",
    "            gen_texts = [output.outputs[0].text for output in outputs]\n",
    "        cleaner()\n",
    "    \n",
    "        results_list.extend(gen_texts)  \n",
    "        predictions.extend([compute_predctions(gen_text) for gen_text in gen_texts])\n",
    "        \n",
    "    # Return results if needed\n",
    "    return {'labels': results_list, 'predictions': predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b444db3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.550153Z",
     "iopub.status.busy": "2024-08-05T15:02:08.549486Z",
     "iopub.status.idle": "2024-08-05T15:02:08.554583Z",
     "shell.execute_reply": "2024-08-05T15:02:08.553718Z"
    },
    "papermill": {
     "duration": 0.064088,
     "end_time": "2024-08-05T15:02:08.557004",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.492916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_responses(df, model, device, results, index):\n",
    "    results[index] = get_llm_response(df, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2317a395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.592263Z",
     "iopub.status.busy": "2024-08-05T15:02:08.591976Z",
     "iopub.status.idle": "2024-08-05T15:02:08.596431Z",
     "shell.execute_reply": "2024-08-05T15:02:08.595621Z"
    },
    "papermill": {
     "duration": 0.022954,
     "end_time": "2024-08-05T15:02:08.598878",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.575924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad88cb9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.635033Z",
     "iopub.status.busy": "2024-08-05T15:02:08.634771Z",
     "iopub.status.idle": "2024-08-05T15:02:08.641137Z",
     "shell.execute_reply": "2024-08-05T15:02:08.640297Z"
    },
    "papermill": {
     "duration": 0.024236,
     "end_time": "2024-08-05T15:02:08.643056",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.618820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_predctions(response: str) -> list[float]:\n",
    "    counts = {'A': 0, 'B': 0, 'AB': 0}\n",
    "    elements = response.split(',')\n",
    "    elements = [ele.strip() for ele in elements]\n",
    "    for element in elements:\n",
    "        if element in counts:\n",
    "            counts[element] += 1\n",
    "    counts_list = [counts['A'], counts['B'], counts['AB']]\n",
    "#     print(counts)\n",
    "    probabilities = np.round(softmax(counts_list), 3)\n",
    "    return probabilities.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42b753d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.675355Z",
     "iopub.status.busy": "2024-08-05T15:02:08.674760Z",
     "iopub.status.idle": "2024-08-05T15:02:08.682896Z",
     "shell.execute_reply": "2024-08-05T15:02:08.682076Z"
    },
    "papermill": {
     "duration": 0.026347,
     "end_time": "2024-08-05T15:02:08.684844",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.658497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_dataframe(row):\n",
    "    prompts = eval(row['prompt'], {\"null\": ['null']})\n",
    "    response_as = eval(row['response_a'], {\"null\": ['null']})\n",
    "    response_bs = eval(row['response_b'], {\"null\": ['null']})\n",
    "    \n",
    "    new_rows = []\n",
    "    for idx, (prompt, response_a, response_b) in enumerate(zip(prompts, response_as, response_bs)):\n",
    "        new_row = row.copy()\n",
    "        new_row['prompt'] = prompt\n",
    "        new_row['response_a'] = response_a\n",
    "        new_row['response_b'] = response_b\n",
    "        new_rows.append(new_row)\n",
    "    \n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae7c54",
   "metadata": {
    "papermill": {
     "duration": 0.015013,
     "end_time": "2024-08-05T15:02:08.715211",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.700198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bddf0267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.747396Z",
     "iopub.status.busy": "2024-08-05T15:02:08.746672Z",
     "iopub.status.idle": "2024-08-05T15:02:08.760642Z",
     "shell.execute_reply": "2024-08-05T15:02:08.759791Z"
    },
    "papermill": {
     "duration": 0.032373,
     "end_time": "2024-08-05T15:02:08.762653",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.730280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(constants.TEST_PATH)\n",
    "# df_ = df_[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f236359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.795680Z",
     "iopub.status.busy": "2024-08-05T15:02:08.794946Z",
     "iopub.status.idle": "2024-08-05T15:02:08.814249Z",
     "shell.execute_reply": "2024-08-05T15:02:08.812988Z"
    },
    "papermill": {
     "duration": 0.038321,
     "end_time": "2024-08-05T15:02:08.816286",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.777965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.17 ms, sys: 294 µs, total: 6.46 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply the function to each row and concatenate the results\n",
    "split_df = pd.concat([expand_dataframe(row) for _, row in df_.iterrows()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9f4d8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.848683Z",
     "iopub.status.busy": "2024-08-05T15:02:08.848026Z",
     "iopub.status.idle": "2024-08-05T15:02:08.862145Z",
     "shell.execute_reply": "2024-08-05T15:02:08.861098Z"
    },
    "papermill": {
     "duration": 0.033049,
     "end_time": "2024-08-05T15:02:08.864688",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.831639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.74 ms, sys: 184 µs, total: 4.92 ms\n",
      "Wall time: 7.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = split_df[\"id\"]\n",
    "data['prompt'] = make_prompt(split_df[\"prompt\"], split_df[\"response_a\"], split_df[\"response_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a0a2702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.896861Z",
     "iopub.status.busy": "2024-08-05T15:02:08.896520Z",
     "iopub.status.idle": "2024-08-05T15:02:08.909514Z",
     "shell.execute_reply": "2024-08-05T15:02:08.908534Z"
    },
    "papermill": {
     "duration": 0.031797,
     "end_time": "2024-08-05T15:02:08.912037",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.880240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant.&lt;|end|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant.&lt;|end|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant.&lt;|end|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1233961</td>\n",
       "      <td>&lt;|system|&gt;\\nYou are a helpful assistant.&lt;|end|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt\n",
       "0   136060  <|system|>\\nYou are a helpful assistant.<|end|...\n",
       "1   211333  <|system|>\\nYou are a helpful assistant.<|end|...\n",
       "2  1233961  <|system|>\\nYou are a helpful assistant.<|end|...\n",
       "3  1233961  <|system|>\\nYou are a helpful assistant.<|end|..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ea0c55d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:08.949493Z",
     "iopub.status.busy": "2024-08-05T15:02:08.948712Z",
     "iopub.status.idle": "2024-08-05T15:02:09.109720Z",
     "shell.execute_reply": "2024-08-05T15:02:09.108763Z"
    },
    "papermill": {
     "duration": 0.179735,
     "end_time": "2024-08-05T15:02:09.111817",
     "exception": false,
     "start_time": "2024-08-05T15:02:08.932082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24425c81",
   "metadata": {
    "papermill": {
     "duration": 0.015716,
     "end_time": "2024-08-05T15:02:09.143668",
     "exception": false,
     "start_time": "2024-08-05T15:02:09.127952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inferencing through Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ca4d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:09.178053Z",
     "iopub.status.busy": "2024-08-05T15:02:09.177767Z",
     "iopub.status.idle": "2024-08-05T15:02:11.677847Z",
     "shell.execute_reply": "2024-08-05T15:02:11.676793Z"
    },
    "papermill": {
     "duration": 2.519957,
     "end_time": "2024-08-05T15:02:11.680180",
     "exception": false,
     "start_time": "2024-08-05T15:02:09.160223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n",
      "  warnings.warn(\n",
      "Processed prompts: 100%|██████████| 4/4 [00:02<00:00,  1.99it/s, est. speed input: 2047.99 toks/s, output: 19.94 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Total time: 2.49 seconds\n",
      "CPU times: user 2.47 s, sys: 35.2 ms, total: 2.51 s\n",
      "Wall time: 2.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "st = time()\n",
    "\n",
    "N_SAMPLES = data.shape[0]\n",
    "half = round(N_SAMPLES)\n",
    "sub1 = data[0:half].copy()\n",
    "# sub2 = data[half:N_SAMPLES].copy()\n",
    "\n",
    "results = {}\n",
    "\n",
    "t0 = Thread(target=llm_responses, args=(sub1, model_0, device0, results, 0))\n",
    "# t1 = Thread(target=llm_responses, args=(sub2, model_1, device1, results, 1))\n",
    "\n",
    "t0.start()\n",
    "# t1.start()\n",
    "\n",
    "t0.join()\n",
    "# t1.join()\n",
    "\n",
    "print(f\"Processing complete. Total time: {time() - st:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d6b0b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:11.723437Z",
     "iopub.status.busy": "2024-08-05T15:02:11.722427Z",
     "iopub.status.idle": "2024-08-05T15:02:11.727042Z",
     "shell.execute_reply": "2024-08-05T15:02:11.726144Z"
    },
    "papermill": {
     "duration": 0.027343,
     "end_time": "2024-08-05T15:02:11.729311",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.701968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d50ad7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:11.770176Z",
     "iopub.status.busy": "2024-08-05T15:02:11.769456Z",
     "iopub.status.idle": "2024-08-05T15:02:11.774942Z",
     "shell.execute_reply": "2024-08-05T15:02:11.773986Z"
    },
    "papermill": {
     "duration": 0.027432,
     "end_time": "2024-08-05T15:02:11.776962",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.749530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = results[0]['predictions'].copy()\n",
    "# predictions.extend(results[1]['predictions'].copy())\n",
    "data['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cbf44cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:11.810288Z",
     "iopub.status.busy": "2024-08-05T15:02:11.810013Z",
     "iopub.status.idle": "2024-08-05T15:02:11.815991Z",
     "shell.execute_reply": "2024-08-05T15:02:11.815075Z"
    },
    "papermill": {
     "duration": 0.025125,
     "end_time": "2024-08-05T15:02:11.818247",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.793122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a398e42b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:11.860153Z",
     "iopub.status.busy": "2024-08-05T15:02:11.859403Z",
     "iopub.status.idle": "2024-08-05T15:02:11.874304Z",
     "shell.execute_reply": "2024-08-05T15:02:11.873514Z"
    },
    "papermill": {
     "duration": 0.03479,
     "end_time": "2024-08-05T15:02:11.876340",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.841550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_lists(list_of_lists):\n",
    "    return [round(sum(x), 3) for x in zip(*list_of_lists)]\n",
    "\n",
    "# Group by 'id' and sum the 'predictions' lists, then round\n",
    "result_df = data.groupby('id')['predictions'].apply(sum_lists).reset_index()\n",
    "result_df['predictions'] = result_df['predictions'].apply(\n",
    "    lambda x: [round(p, 3) for p in softmax(x)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c01631",
   "metadata": {
    "papermill": {
     "duration": 0.016068,
     "end_time": "2024-08-05T15:02:11.908751",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.892683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9603788b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T15:02:11.942785Z",
     "iopub.status.busy": "2024-08-05T15:02:11.942021Z",
     "iopub.status.idle": "2024-08-05T15:02:11.963678Z",
     "shell.execute_reply": "2024-08-05T15:02:11.962809Z"
    },
    "papermill": {
     "duration": 0.040704,
     "end_time": "2024-08-05T15:02:11.965573",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.924869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060           0.252           0.497       0.252\n",
       "1   211333           0.297           0.465       0.238\n",
       "2  1233961           0.709           0.148       0.143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = result_df[[\"id\"]].copy()\n",
    "\n",
    "sub_df[constants.TARGETS] = result_df['predictions'].to_list()\n",
    "sub_df.to_csv(constants.SUBMISSION_PATH, index=False)\n",
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2e6f7",
   "metadata": {
    "papermill": {
     "duration": 0.016243,
     "end_time": "2024-08-05T15:02:11.998344",
     "exception": false,
     "start_time": "2024-08-05T15:02:11.982101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5491951,
     "sourceId": 9100297,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5499143,
     "sourceId": 9111125,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 91359,
     "modelInstanceId": 66443,
     "sourceId": 79077,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 225.156957,
   "end_time": "2024-08-05T15:02:15.426399",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-05T14:58:30.269442",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "30dcbc1c0f4a4995bf6f1eb0fc991684": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b07a8f5692d4bf1985d5e1b41e745b1",
       "placeholder": "​",
       "style": "IPY_MODEL_6b70ccd32a3444a2b8a2a2b9c9c7411e",
       "tabbable": null,
       "tooltip": null,
       "value": ""
      }
     },
     "55340936045f4123afa2e62013e60dfe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57a6d6d7389f42ebbe6c1c6e63773126": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5c8f9eed9a114a739f9d1ce88d7319cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64ce8d7a0d384128b2aab3b9f34bf766",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c325aac28be44aa2a969fbdc866afa11",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "5c9ea8f14cc5470a87157966aa4af019": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_30dcbc1c0f4a4995bf6f1eb0fc991684",
        "IPY_MODEL_5c8f9eed9a114a739f9d1ce88d7319cd",
        "IPY_MODEL_99add8001009437ca600a65fc8361200"
       ],
       "layout": "IPY_MODEL_55340936045f4123afa2e62013e60dfe",
       "tabbable": null,
       "tooltip": null
      }
     },
     "64ce8d7a0d384128b2aab3b9f34bf766": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b70ccd32a3444a2b8a2a2b9c9c7411e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8b07a8f5692d4bf1985d5e1b41e745b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99add8001009437ca600a65fc8361200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c0c8d6158fdd446a9e5137e807de1905",
       "placeholder": "​",
       "style": "IPY_MODEL_57a6d6d7389f42ebbe6c1c6e63773126",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:41&lt;00:00, 20.40s/it]\n"
      }
     },
     "c0c8d6158fdd446a9e5137e807de1905": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c325aac28be44aa2a969fbdc866afa11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
